---
title: "Multiple Regression"
author: "Albert Y. Kim"
date: "Last updated on `r Sys.Date()`"
output: html_document
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(glmnet)
library(tidyverse)
library(broom)
library(plotly)
library(stringr)
```

**Note**: The source code for this Shiny app is available on <a target="_blank" class="page-link" href="https://github.com/rudeboybert/MATH218/blob/gh-pages/assets/regularization/regularization_ROC.Rmd">GitHub</a>.



## Data

Let's do an exploratory data analysis of the data for problem set 4. For $i=1, \ldots, 400$ individuals, we are interested in their credit
card balance. Alas, no sampling information is provided, so we can't make any statements on the generalizability of this analysis. Recall our model formulation: $y_i = f(\vec{x}_i) + \epsilon_i$:

* $y_i$: Credit card balance
* $x_{1,i}$: Income in $10K
* $x_{2,i}$: Credit limit in $
* $x_{3,i}$: Credit rating
* $x_{4,i}$: Age
* $x_{5,i}$: Number of credit cards
* $x_{6,i}$: Years of education

Here is a random sample of 10 of the 400 rows:

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10}
library(tidyverse)
credit <- read_csv("http://www-bcf.usc.edu/~gareth/ISL/Credit.csv") %>%
  select(-X1) %>%
  mutate(ID = 1:n()) %>% 
  select(ID, Balance, Income, Limit, Rating, Age, Cards, Education)
credit %>% 
  sample_n(10) %>% 
  knitr::kable()
```

Let's view the points in an interactive 3D plot:

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10}
base_plot <-
  plot_ly(showlegend=FALSE) %>%
  add_markers(
    x = credit$Income,
    y = credit$Limit,
    z = credit$Balance,
    hoverinfo = 'text',
    text = ~paste("x1 - Income: ", credit$Income, "</br> x2 - Limit: ", credit$Limit, "</br> y - Balance: ", credit$Balance)
  ) %>%
  layout(
    scene = list(
      xaxis = list(title = "x1 - Income (in $10K)"),
      yaxis = list(title = "x2 - Limit ($)"),
      zaxis = list(title = "y - Balance ($)")
    )
  )
base_plot
```







## Two Simple Models

Let's now consider two models:

1. **Naive Model**: Uses no predictor information
1. **Regression Model**: Fits a linear regression with
    + $x_1$: Income
    + $x_2$: Credit limit

#### 1. Naive Model

The average balance in this data set is $\overline{y}$ = \$`r mean(credit$Balance) %>% round(2)`. So for
any point $(x_1, x_2)$ we would predict \$`r mean(credit$Balance) %>% round(2)`. Let's view this in an interactive 3D plot:

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10}
x_grid <- seq(from=min(credit$Income), to=max(credit$Income), length=100)
y_grid <- seq(from=min(credit$Limit), to=max(credit$Limit), length=200)
z_grid <- expand.grid(x_grid, y_grid) %>%
  tbl_df() %>%
  rename(
    x_grid = Var1,
    y_grid = Var2
  ) %>%
  mutate(z = mean(credit$Balance)) %>%
  .[["z"]] %>%
  matrix(nrow=length(x_grid)) %>%
  t()

plot_ly(showscale=FALSE) %>%
  add_markers(
    x = credit$Income,
    y = credit$Limit,
    z = credit$Balance,
    hoverinfo = 'text',
    text = ~paste("x1 - Income: ", credit$Income, "</br> x2 - Limit: ", credit$Limit, "</br> y - Balance: ", credit$Balance)
  ) %>%
  layout(
    scene = list(
      xaxis = list(title = "x1 - Income (in $10K)"),
      yaxis = list(title = "x2 - Limit ($)"),
      zaxis = list(title = "y - Balance ($)")
    )
  ) %>%
  add_surface(
    x = x_grid,
    y = y_grid,
    z = z_grid
  )
```


#### 2. Regression Model

Let's now fit a linear regression 

$$
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2\\
\mbox{Balance} = \beta_0 + \beta_1\mbox{Income} + \beta_2\mbox{Limit}
$$

using `lm(Balance ~ Income + Limit)`. The *least-squares estimates* of the three
$\beta$ *coefficients* (the intercept and the two slopes) are:

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10}
model_formula <- as.formula("Balance ~ Income + Limit")
model_lm <- credit %>% 
  # mutate(
  #   Income = Income - mean(Income),
  #   Limit = Limit - mean(Limit)
  #   ) %>% 
  lm(model_formula , data=.)
tidy(model_lm) %>%
  select(term, estimate) %>% 
  knitr::kable(digits=2)
```

Hence we can computed fitted values:

$$
\widehat{y} = \widehat{\beta}_0 + \widehat{\beta}_1x_1 + \widehat{\beta}_2x_2\\
\widehat{\mbox{Balance}} = \widehat{\beta}_0 + \widehat{\beta}_1\mbox{Income} + \widehat{\beta}_2\mbox{Limit}\\
\widehat{\mbox{Balance}} = -385.18 - 7.66 \times \mbox{Income} + 0.26\times\mbox{Limit}\\
$$

Note:

* Where as in simple linear regression based on observations $(x_i, y_i)$ with a
single predictor yielding a line
* We are now dealing with multiple linear regression based on observations $(x_{1,i}, x_{2,i}, y_i)$ with two predictors
yielding a plane. The plane corresponds to our fitted values. Let's view these in an interactive 3D plot:

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10}
x_grid <- seq(from=min(credit$Income), to=max(credit$Income), length=100)
y_grid <- seq(from=min(credit$Limit), to=max(credit$Limit), length=200)
z_grid <- expand.grid(x_grid, y_grid) %>%
  tbl_df() %>%
  rename(
    x_grid = Var1,
    y_grid = Var2
  ) %>%
  mutate(z = coef(model_lm)[1] + coef(model_lm)[2]*x_grid + coef(model_lm)[3]*y_grid) %>%
  .[["z"]] %>%
  matrix(nrow=length(x_grid)) %>%
  t()

base_plot %>%
  add_surface(
    x = x_grid,
    y = y_grid,
    z = z_grid
    )
```